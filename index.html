<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>World Models Must Live in Parallel Worlds</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.7;
            color: #333;
            background: #fafafa;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0;
            background: white;
            box-shadow: 0 0 20px rgba(0,0,0,0.05);
        }

        header {
            text-align: center;
            padding: 60px 40px 40px 40px;
            background: white;
        }

        h1 {
            font-size: 2.5em;
            font-weight: 600;
            margin-bottom: 20px;
            color: #1a1a1a;
            line-height: 1.3;
        }

        .venue {
            font-size: 1.05em;
            color: #666;
            margin-bottom: 25px;
        }

        .authors {
            font-size: 1.05em;
            margin-bottom: 12px;
            color: #444;
        }

        .affiliation {
            font-size: 0.95em;
            color: #666;
            margin-bottom: 30px;
            line-height: 1.6;
        }

        .links {
            display: flex;
            justify-content: center;
            gap: 15px;
            flex-wrap: wrap;
            padding-bottom: 30px;
            border-bottom: 1px solid #e5e5e5;
        }

        .links a {
            display: inline-block;
            padding: 10px 24px;
            background: #2563eb;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background 0.2s;
            font-size: 0.95em;
        }

        .links a:hover {
            background: #1d4ed8;
        }

        .content {
            padding: 40px;
        }

        .teaser-section {
            margin-bottom: 50px;
        }

        .teaser-box {
            background: #f8f9fa;
            padding: 40px;
            border-radius: 8px;
            border: 2px dashed #d1d5db;
            text-align: center;
            min-height: 350px;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-direction: column;
            gap: 15px;
        }

        .teaser-box img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }

        .placeholder-text {
            color: #9ca3af;
            font-size: 1em;
            font-style: italic;
        }

        .figure-caption {
            margin-top: 15px;
            font-size: 0.95em;
            color: #666;
            line-height: 1.6;
            text-align: left;
        }

        p {
            margin-bottom: 18px;
            font-size: 1.05em;
            line-height: 1.7;
        }

        section {
            margin: 50px 0;
        }

        h2 {
            font-size: 1.8em;
            margin-bottom: 20px;
            color: #1a1a1a;
            font-weight: 600;
        }

        h3 {
            font-size: 1.4em;
            margin: 30px 0 15px 0;
            color: #1a1a1a;
            font-weight: 600;
        }

        strong {
            font-weight: 600;
            color: #1a1a1a;
        }

        .highlight-box {
            background: #fef3c7;
            padding: 25px;
            border-radius: 8px;
            margin: 25px 0;
            border-left: 4px solid #f59e0b;
        }

        .highlight-box p:last-child {
            margin-bottom: 0;
        }

        ul {
            margin: 15px 0 20px 20px;
        }

        li {
            margin-bottom: 10px;
            font-size: 1.05em;
            line-height: 1.7;
        }

        .pillars-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .pillar-card {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-top: 3px solid #2563eb;
        }

        .pillar-card h4 {
            font-size: 1.2em;
            margin-bottom: 12px;
            color: #1a1a1a;
            font-weight: 600;
        }

        .pillar-card p {
            font-size: 1em;
            margin-bottom: 12px;
        }

        .pillar-card p:last-child {
            margin-bottom: 0;
        }

        .citation-box {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.6;
            border: 1px solid #e5e5e5;
        }

        footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            border-top: 1px solid #e5e5e5;
            margin-top: 50px;
        }

        footer p {
            color: #666;
            font-size: 0.95em;
            margin-bottom: 8px;
        }

        footer p:last-child {
            margin-bottom: 0;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2em;
            }

            header {
                padding: 40px 20px 30px 20px;
            }

            .content {
                padding: 30px 20px;
            }

            h2 {
                font-size: 1.5em;
            }

            .pillars-grid {
                grid-template-columns: 1fr;
            }

            .teaser-box {
                padding: 30px 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>World Models Must Live in Parallel Worlds</h1>
            <div class="venue">NeurIPS 2025 Workshop: LAW 2025</div>
            <div class="authors">
                <strong>Sahithya Ravi*</strong>, <strong>Aditya Chinchure*</strong>, Pushkar Shukla, Vered Shwartz, Leonid Sigal
            </div>
            <div class="affiliation">
                <sup>1</sup>The University of British Columbia, <sup>2</sup>Vector Institute of AI, <sup>3</sup>Toyota Technological Institute at Chicago<br>
                *Equal contribution
            </div>
            <div class="links">
                <a href="https://openreview.net/pdf?id=sj9Nyke43S" target="_blank">ðŸ“„ Paper</a>
            </div>
        </header>

        <div class="content">
            <div class="teaser-section">
                <div class="teaser-box">
                    <img src="assets/robot_teaser.png" alt="Search and rescue robot scenario" onerror="this.style.display='none'">
                    
                </div>
                <div class="figure-caption">
                    A search-and-rescue robot in a collapsed building: Should it move the precariously balanced slab? Current world models may predict trajectory (1), but counterfactual simulation (CfS) enables evaluating counterfactual trajectories (2, 3, 4) that are crucial for safety.
                </div>
            </div>

            <p>
                Real-world environments present agents with novel, out-of-distribution scenarios that require more than pattern matching to navigate safely. World models learn spatio-temporal representations that enable prediction, interaction, and simulation. Yet most current world models focus on predicting the most likely future, missing the ability to reason about alternative outcomes.
            </p>

            <p>
                We introduce <strong>SPIKE</strong>, an inference-time framework that quantifies Bayesian Surprise as the belief update triggered by new visual evidence in the video stream. By identifying moments where new observations conflict with prior expectations, SPIKE naturally discovers the most salient and informative frames. Since zero-shot Video-LLM beliefs are often suboptimal, we develop <strong>SPIKE-RL</strong>, which leverages group relative policy optimization (GRPO) to refine belief hypotheses based on caption quality as a reward signal.
            </p>

            <p>
                <strong>We posit that world models must be capable of counterfactual simulation</strong> â€“ the ability to reason about "what if" scenarios. By simulating alternative realities, world models will be more capable, safe, and creative when faced with novel situations. Furthermore, they can transcend mere pattern matching to achieve true causal understanding of the world, a capability central to human intelligence.
            </p>

            <section id="problem">
                <h2>The Case-Based Generalization Crisis</h2>
                
                <p>
                    Generative AI has demonstrated remarkable capabilities in creating text, images and videos that mimic human output. However, for these models to transition from digital content creators to effective agents in the physical world, they require a deeper understanding of how the world works.
                </p>

                <p>
                    Current efforts to build world models focus on predicting future states from past observations, typically by scaling models and exposing them to millions of examples. This approach, while powerful, creates a fundamental generalization gap. The resulting models excel at interpolating within their training data, but falter when asked to extrapolate to novel scenarios. They engage in case-based generalization, effectively imitating the most similar training instances rather than abstracting the underlying physical or causal principles.
                </p>
                
                <div class="highlight-box">
                    <p><strong>This brittleness manifests in critical failures:</strong></p>
                    <ul>
                        <li>Models often lack compositionality, struggling to combine familiar concepts in novel contexts. For example, Veo 2 struggles to generate "a hummingbird flying over a city" because it associates the bird with natural habitats, rather than abstracting hummingbird and flying as transferable concepts.</li>
                        <li>They mistake correlation for causation, producing hallucinations such as people walking backwards in Genie 2.</li>
                        <li>They remain opaque black boxes, unable to explain their reasoning and unsuitable for safety-critical applications.</li>
                    </ul>
                </div>

                <p>
                    Human cognition provides a useful point of reference. When humans encounter a novel situation, we hypothesize alternatives: if a human drives into a school zone, we imagine that children may run into the road, or that a car door may suddenly open. Such counterfactual simulations allow us to substitute, recombine, and adapt knowledge flexibly, enabling robustness in out-of-distribution settings.
                </p>
            </section>

            <section id="counterfactual">
                <h2>Counterfactual Simulation</h2>

                <h3>Definitions</h3>
                <p>
                    A <strong>counterfactual</strong> is a hypothetical "what-if" that changes a specific aspect of the world and examines how the outcome would differ, allowing us to reason about alternative outcomes. Within Pearl's Ladder of Causation, counterfactuals sit at the highest level. Beyond association (observing correlations) and intervention (predicting the effects of actions), they answer questions of the form, "What would have happened if I had acted differently?"
                </p>

                <p>
                    A <strong>counterfactual simulation (CfS)</strong> is an alternative sequence of events generated by a world model that explores what could have happened had a specific event been different. To formalize, we define an event (e<sub>t</sub>) as a single unit combining a state and an action at time t. A trajectory (Ï‰) is a sequence of these events over time.
                </p>

                <p>
                    Consider a factual trajectory (Ï‰<sub>fact</sub>) that represents the most likely sequence of events. A counterfactual trajectory (Ï‰<sub>cf</sub>) is a hypothetical alternative created by performing an intervention at a specific step k, replacing the factual event with a different, hypothetical event. This trajectory is constructed by following a three-part process:
                </p>

                <ul>
                    <li>For all steps leading up to the intervention (t < k), the counterfactual events are identical to the factual ones</li>
                    <li>At the intervention point (t = k), the factual event is replaced with a hypothetical alternative</li>
                    <li>For all steps following the intervention (t > k), subsequent events are generated by the world model, simulating the consequences of the counterfactual change</li>
                </ul>

                <p>
                    This process generates a new trajectory that is identical to the factual one up to the intervention point but diverges afterward due to the change at step k, creating parallel worlds that enable reasoning about alternative outcomes.
                </p>
            </section>

            <section id="position">
                <h2>Alternative Views and Our Position</h2>

                <p>
                    A common prevailing view is that case-based generalization will be overcome naturally from scaling up generative models with more data and compute. Others advocate for test-time scaling: allocating greater compute at inference to improve reasoning abilities and generalization.
                </p>

                <p>
                    <strong>We believe that scaling data, models or test-time compute alone is not a viable path forward to robust world modeling</strong>, for the following reasons:
                </p>

                <ul>
                    <li>High quality human data is finite, pushing reliance on synthetic data that risks model collapse as models train on their own outputs. The energy and water demands of large data centers raise sustainability concerns and question the long-term viability of continued scaling.</li>
                    <li>Large-scale models are data inefficient. LLMs train on trillions of tokens, far exceeding a child's linguistic exposure and still lack robust world understanding.</li>
                    <li>Allocating more compute at test-time is not a cure-all for a flawed underlying model. A model that doesn't grasp intuitive physics, like object permanence, will just explore a larger tree of physically implausible outcomes, no matter how much compute is thrown at it.</li>
                </ul>
            </section>

            <section id="path-forward">
                <h2>The Path Forward: Three Pillars</h2>
                
                <p>
                    Effective counterfactual simulation requires a strong underlying causal framework for the world the model is trained on, and a structured process to trigger, generate, store, and use counterfactual simulations. We propose a three-pillar approach:
                </p>

                <div class="pillars-grid">
                    <div class="pillar-card">
                        <h4>Pillar 1: The Reasoning Process</h4>
                        <p><strong>Activation:</strong> World models must decide when to simulate counterfactuals by identifying causally significant "activation events" based on their impact on future trajectories.</p>
                        <p><strong>Inference:</strong> When an activation event is identified, perform targeted interventions to simulate consequences, balancing decision importance and uncertainty against computational cost.</p>
                        <p><strong>Adaptation:</strong> Use CfS outcomes to inform appropriate actions or preventative measures through reasoning methods.</p>
                    </div>

                    <div class="pillar-card">
                        <h4>Pillar 2: Model Architecture Design</h4>
                        <p><strong>Deep Compositionality:</strong> Encode the world as a system of disentangled concepts, objects, and physical rulesâ€”where elemental building blocks can combine to form larger concepts with transferable properties.</p>
                        <p><strong>Hypothesis Canvas:</strong> Use an external memory workspace to instantiate and maintain multiple parallel trajectories, creating distinct subgraphs for each CfS trajectory.</p>
                    </div>

                    <div class="pillar-card">
                        <h4>Pillar 3: Training and Evaluation</h4>
                        <p><strong>Training:</strong> Prioritize interventional prediction objectives that force world models to capture causal relationships rather than mere correlations.</p>
                        <p><strong>Evaluation:</strong> Verify adherence to logical and physical constraints (e.g., conservation laws, plausible dynamics) rather than reconstruction accuracy, given the scarcity of ground truth for counterfactuals.</p>
                    </div>
                </div>
            </section>

            <section id="implications">
                <h2>Discussion</h2>
                
                <p>
                    Developing world models with counterfactual simulation (CfS) will enable robustness in critical domains like robotics and healthcare, where reasoning about novel situations is key to safe and effective operation. However, there are technical and safety challenges that need to be met.
                </p>

                <h3>Key Research Questions</h3>
                <ul>
                    <li><strong>How can we build these models?</strong> Building a single, all-encompassing causal model is computationally infeasible. A more practical path may involve an ensemble of smaller, context-specific models with specialized memory modules.</li>
                    <li><strong>How would a model initially learn what constitutes a causally significant "activation event"?</strong> The model can leverage statistical uncertainty as a diagnostic signal and proactively seek out surprising scenarios where prediction errors are highest.</li>
                    <li><strong>How would you manage the exponential growth of possible counterfactuals?</strong> Develop mechanisms to generate counterfactuals from most plausible to least plausible, with a dynamically determined counterfactual budget that prioritizes contextually plausible, unexpected, and causally significant scenarios.</li>
                    <li><strong>How do we measure success?</strong> Indirect evaluation through downstream benchmarks and carefully designed simulations with novel constraints can assess CfS capability.</li>
                    <li><strong>What are the ethical implications?</strong> Models that can simulate "what if" scenarios need safeguards to prevent acting on dangerous simulations, with transparent reasoning in human-understandable formats.</li>
                </ul>
            </section>

            <section id="citation">
                <h2>Citation</h2>
                <div class="citation-box">@article{ravi2025counterfactual,
  title={Position: World Models must live in Parallel Worlds},
  author={Ravi, Sahithya and Chinchure, Aditya and Shukla, Pushkar 
          and Shwartz, Vered and Sigal, Leonid},
  journal={NeurIPS 2025 Workshop: LAW 2025},
  year={2025}
}</div>
            </section>
        </div>

        <footer>
            <p><strong>NeurIPS 2025 Workshop: LAW 2025</strong></p>
            <p>Bridging Language, Agent, and World Models for Reasoning and Planning</p>
        </footer>
    </div>
</body>
</html>